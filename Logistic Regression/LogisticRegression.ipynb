{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "606e2850-3f8a-4026-8bbe-89a03f984db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ecf0f08b-21de-4f13-a959-f788eb3009d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression_bin():\n",
    "    def __init__(self, Max_iter, learning_rate, weight = None, intercept=None):\n",
    "        self.Max_iter = Max_iter\n",
    "        self.weight = weight\n",
    "        self.intercept = intercept\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def weight_initial(self, Xshape):\n",
    "        self.weight = np.zeros(Xshape[1])\n",
    "        self.intercept = 0\n",
    "        \n",
    "        return self.weight, self.intercept\n",
    "    \n",
    "    def sigmoid(self, w, x, b):\n",
    "        func = 1 / (1 + np.exp(x.dot(w.transpose()) + b))\n",
    "        return func\n",
    "    \n",
    "    def loss_grad(self, X, y, learning_rate):\n",
    "        self.weight, self.intercept = self.weight_initial(X.shape)\n",
    "        #we use stochatic gradient here\n",
    "        #how to do stochastic gradient descent\n",
    "        #initialize Loss\n",
    "        \n",
    "        \n",
    "        for i in range(self.Max_iter):\n",
    "            idxes = np.arange(len(y))\n",
    "            np.random.shuffle(idxes)\n",
    "            for idx in idxes:\n",
    "                grad_w = (-1) * (y[idx] - self.weight.transpose().dot(X[idx]) - self.intercept) * X[idx] * self.learning_rate\n",
    "                grad_b = (-1) * (y[idx] - self.weight.transpose().dot(X[idx]) - self.intercept) * self.learning_rate\n",
    "                self.weight -=grad_w\n",
    "                self.intercept -= grad_b\n",
    "            Loss = -np.sum(y[idx] * np.log(self.sigmoid(self.weight, X, self.intercept)) + (1-y[idx]) * np.log(1-self.sigmoid(self.weight, X, self.intercept))) / X.shape[0]\n",
    "            if(i % 100 == 0):\n",
    "                print(\"loss of the func is:\", Loss)\n",
    "            \n",
    "        return self.weight, self.intercept\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.weight, self.intercept = self.loss_grad(X, y, self.learning_rate)\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        \n",
    "        y_pred = X.dot(self.weight.transpose()) + self.intercept\n",
    "        y_pred[y_pred > 0.5] = 1\n",
    "        y_pred[y_pred < 0.5] = 0\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    def score(self, y_true, y_pred):\n",
    "        return np.sum(y_true == y_pred)/ len(y_true)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3309ac27-11e8-469b-9e7f-0c28a48f6a7f",
   "metadata": {},
   "source": [
    "## A test Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "41599d4a-f38a-48be-b3a5-e49a91f09bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples = 100, n_features=2, n_informative = 2, n_redundant=0, n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f9b51307-c18e-4dcc-ac1a-af56493c9f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "10b54332-4c20-4635-944e-49e601bf0d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "21eddf53-65db-4315-af64-909cb5c7c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logist = LogisticRegression_bin(Max_iter=1000, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "9423b9a8-2313-42a9-a567-52d6eeb8e776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegression_bin at 0x29565634a60>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Logist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327288e6-adb8-472a-9403-087045e882ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logist.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f8463d4b-e1e1-4a9e-9d5e-1eb75a88382f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1.])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Logist.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d0b2f5f5-17ab-43dc-bc2b-3d9b9c5df597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Logist.score(y, Logist.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9432c61e-da88-4540-8bac-f6c3a711fc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.44783361, -0.11487274])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Logist.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d5929869-b249-474a-9f45-5ec3ce6c4f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4900104523098505"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Logist.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3079d044-0aec-4473-99bb-0d1b2f6b5c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6f9c612b-ffd2-4f81-a6f2-f2e6e5d4067e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49512225, 1.4235143 ])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bd2e74-6fb1-41c4-bcb1-7294699db42e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
